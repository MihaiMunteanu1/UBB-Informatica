{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T13:31:17.954111Z",
     "start_time": "2025-04-22T13:31:17.233111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from array import array\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "import time\n",
    "\n",
    "os.environ[\"VISION_KEY\"] = \"EG1ieEDO7QOpKmhTVhHNZ1FaWoBDvsTqH8SsxiIewGFCttaPpmnuJQQJ99BCAC5RqLJXJ3w3AAAFACOGNK2e\"\n",
    "os.environ[\"VISION_ENDPOINT\"] = \"https://munteanumihai.cognitiveservices.azure.com/\"\n",
    "\n",
    "'''\n",
    "Authenticate\n",
    "Authenticates your credentials and creates a client.\n",
    "'''\n",
    "subscription_key = os.environ[\"VISION_KEY\"]\n",
    "endpoint = os.environ[\"VISION_ENDPOINT\"]\n",
    "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))\n",
    "'''\n",
    "END - Authenticate\n",
    "'''"
   ],
   "id": "6eb972b3e954c7f5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEND - Authenticate\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T13:31:21.126541Z",
     "start_time": "2025-04-22T13:31:19.960201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##img = open(\"test1.png\", \"rb\")\n",
    "#img = open(\"test2.jpeg\", \"rb\")\n",
    "img = open(\"Untitled.png\",\"rb\")\n",
    "#img = open(\"ocr.png\",\"rb\")\n",
    "read_response = computervision_client.read_in_stream(\n",
    "    image=img,\n",
    "    mode=\"Printed\",\n",
    "    raw=True\n",
    ")\n",
    "# print(read_response.as_dict())\n",
    "\n",
    "operation_id = read_response.headers['Operation-Location'].split('/')[-1]\n",
    "while True:\n",
    "    read_result = computervision_client.get_read_result(operation_id)\n",
    "    if read_result.status not in ['notStarted', 'running']:\n",
    "        break\n",
    "    time.sleep(1)\n",
    "\n",
    "# Print the detected text, line by line\n",
    "result = []\n",
    "if read_result.status == OperationStatusCodes.succeeded:\n",
    "    for text_result in read_result.analyze_result.read_results:\n",
    "        for line in text_result.lines:\n",
    "            print(line.text)\n",
    "            result.append(line.text)\n",
    "\n",
    "print()"
   ],
   "id": "d2d69da628cce56d",
   "outputs": [
    {
     "ename": "ComputerVisionOcrErrorException",
     "evalue": "Operation returned an invalid status code 'PermissionDenied'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mComputerVisionOcrErrorException\u001B[0m           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m img \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUntitled.png\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m#img = open(\"ocr.png\",\"rb\")\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m read_response \u001B[38;5;241m=\u001B[39m \u001B[43mcomputervision_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_in_stream\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mimage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mPrinted\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mraw\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[0;32m      9\u001B[0m \u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# print(read_response.as_dict())\u001B[39;00m\n\u001B[0;32m     12\u001B[0m operation_id \u001B[38;5;241m=\u001B[39m read_response\u001B[38;5;241m.\u001B[39mheaders[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mOperation-Location\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m'\u001B[39m)[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\azure\\cognitiveservices\\vision\\computervision\\operations\\_computer_vision_client_operations.py:1709\u001B[0m, in \u001B[0;36mComputerVisionClientOperationsMixin.read_in_stream\u001B[1;34m(self, image, language, pages, model_version, reading_order, custom_headers, raw, callback, **operation_config)\u001B[0m\n\u001B[0;32m   1706\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_client\u001B[38;5;241m.\u001B[39msend(request, stream\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moperation_config)\n\u001B[0;32m   1708\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;241m202\u001B[39m]:\n\u001B[1;32m-> 1709\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m models\u001B[38;5;241m.\u001B[39mComputerVisionOcrErrorException(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_deserialize, response)\n\u001B[0;32m   1711\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m raw:\n\u001B[0;32m   1712\u001B[0m     client_raw_response \u001B[38;5;241m=\u001B[39m ClientRawResponse(\u001B[38;5;28;01mNone\u001B[39;00m, response)\n",
      "\u001B[1;31mComputerVisionOcrErrorException\u001B[0m: Operation returned an invalid status code 'PermissionDenied'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T17:14:08.857586Z",
     "start_time": "2025-03-19T17:14:08.850128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get/define the ground truth\n",
    "#groundTruth = [\"Google Cloud\", \"Platform\"]\n",
    "#groundTruth = [\"Succes in rezolvarea\", \"tEMELOR la\", \"LABORAtoaree de\", \"Inteligenta Artificiala!\"]\n",
    "groundTruth=[\"Seat\",\"Ateca\",\"2019\"]\n",
    "#groundTruth=[\"Seat\",\"Vw\",\"Ateca\",\"Laborator\",\"2019\"]\n",
    "#groundTruth=[\"Seat Ateca\",\"Vlad Mutu\"]\n",
    "\n",
    "# compute the performance\n",
    "noOfCorrectLines = sum(i == j for i, j in zip(result, groundTruth))\n",
    "print(noOfCorrectLines)"
   ],
   "id": "1c93efe1bbbe483b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "de verificat cu distantaHamming daca cuvintele din poza sunt la fel cu cele din groundTruth\n",
    "Iaccard: (A intersectat cu B) / (A reunit cu B)\n",
    "\n",
    "2. pun eu unde se afla fiecare cuvant si trebuie sa-mi dea la fel\n",
    "3. cum as putea face sa identifice mai bine scrisul de mana, (de gandit si scris ca comentariu)"
   ],
   "id": "50bb0818b4873c72"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h3>1. A: Hamming: pozitia caracterelor</h3>",
   "id": "fe96a8556dba74ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T17:14:11.026296Z",
     "start_time": "2025-03-19T17:14:11.011382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scipy.spatial.distance import hamming\n",
    "\n",
    "total_distance = 0\n",
    "for gt_word, res_word in zip(groundTruth, result):\n",
    "    max_len = max(len(gt_word), len(res_word))\n",
    "    gt_word = gt_word.ljust(max_len)\n",
    "    res_word = res_word.ljust(max_len)\n",
    "    distance = hamming(list(gt_word), list(res_word)) * max_len\n",
    "    print(f\"Hamming distance between '{gt_word.strip()}' and '{res_word.strip()}': {distance}\")\n",
    "    total_distance += distance\n",
    "\n",
    "print(f\"Total Hamming distance: {total_distance}\")"
   ],
   "id": "ec093f6e5e035622",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming distance between 'Seat' and 'Seat': 0.0\n",
      "Hamming distance between 'Ateca' and 'Jeg': 5.0\n",
      "Hamming distance between '2019' and 'Ateca': 5.0\n",
      "Total Hamming distance: 10.0\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h3>1. B: Jaccard: absenta sau prezenta caracterelor</h3>\n",
   "id": "77374dfc89f85b29"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T17:14:12.340270Z",
     "start_time": "2025-03-19T17:14:12.317646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "import numpy as np\n",
    "\n",
    "total_jaccard = 0\n",
    "for gt_word, res_word in zip(groundTruth, result):\n",
    "    gt_set = set(gt_word)\n",
    "    res_set = set(res_word)\n",
    "    union_len = len(gt_set.union(res_set))\n",
    "    intersection_len = len(gt_set.intersection(res_set))\n",
    "    if union_len != 0:\n",
    "        jaccard_index = intersection_len / union_len\n",
    "    else:\n",
    "        jaccard_index = 0\n",
    "    print(f\"Jaccard index between '{gt_word}' and '{res_word}': {jaccard_index}\")\n",
    "    total_jaccard += jaccard_index\n",
    "\n",
    "print(f\"Total Jaccard index: {total_jaccard}\")"
   ],
   "id": "c0f584c0d7fbca98",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard index between 'Seat' and 'Seat': 1.0\n",
      "Jaccard index between 'Ateca' and 'Jeg': 0.14285714285714285\n",
      "Jaccard index between '2019' and 'Ateca': 0.0\n",
      "Total Jaccard index: 1.1428571428571428\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h3> 2 </h3>",
   "id": "c2ac038a6e81fd5b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T17:14:14.414353Z",
     "start_time": "2025-03-19T17:14:14.373739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "\n",
    "result2 = []\n",
    "if read_result.status == OperationStatusCodes.succeeded:\n",
    "    for text_result in read_result.analyze_result.read_results:\n",
    "        for line in text_result.lines:\n",
    "            print(f\"Text: {line.text}\")\n",
    "            print(f\"Bounding Box: {line.bounding_box}\")\n",
    "            result2.append((line.text, line.bounding_box))\n",
    "\n",
    "print()\n",
    "\n",
    "# expected_locations = {\n",
    "#     \"Succes in rezolvarea\": \"top-left\",\n",
    "#     \"tEMELOR la\": \"top-right\",\n",
    "#     \"LABORAtoaree de\": \"bottom-left\",\n",
    "#     \"Inteligenta Artificiala!\": \"bottom-right\"\n",
    "# }\n",
    "expected_locations = {\n",
    "    \"Seat\": \"top-left\",\n",
    "    \"Ateca\": \"center\",\n",
    "    \"2019\": \"bottom-right\"\n",
    "}\n",
    "# expected_locations = {\n",
    "#     \"Seat\": \"top-left\",\n",
    "#     \"Vw\": \"top-center\",\n",
    "#     \"Ateca\": \"center\",\n",
    "#     \"2019\": \"bottom-right\",\n",
    "#     \"Laborator\": \"bottom-center\"\n",
    "# }\n",
    "\n",
    "\n",
    "def determine_location(bounding_box, image_width, image_height):\n",
    "    x_coords = [bounding_box[i] for i in range(0, len(bounding_box), 2)]\n",
    "    y_coords = [bounding_box[i+1] for i in range(0, len(bounding_box), 2)]\n",
    "    avg_x = sum(x_coords) / len(x_coords) / image_width\n",
    "    avg_y = sum(y_coords) / len(y_coords) / image_height\n",
    "\n",
    "    if avg_x < 0.33 and avg_y < 0.33:\n",
    "        return \"top-left\"\n",
    "    elif 0.66 > avg_x >= 0.33 > avg_y:\n",
    "        return \"top-center\"\n",
    "    elif avg_x >= 0.66 and avg_y < 0.33:\n",
    "        return \"top-right\"\n",
    "    elif avg_x < 0.33 <= avg_y < 0.66:\n",
    "        return \"left-center\"\n",
    "    elif avg_x >= 0.66 > avg_y >= 0.33:\n",
    "        return \"right-center\"\n",
    "    elif avg_x < 0.33 and avg_y >= 0.66:\n",
    "        return \"bottom-left\"\n",
    "    elif 0.33 <= avg_x < 0.66 <= avg_y:\n",
    "        return \"bottom-center\"\n",
    "    elif avg_x >= 0.66 and avg_y >= 0.66:\n",
    "        return \"bottom-right\"\n",
    "    else:\n",
    "        return \"center\"\n",
    "\n",
    "image = cv2.imread(\"Untitled2.jpg\")\n",
    "image_height, image_width = image.shape[:2]\n",
    "\n",
    "for text, bounding_box in result2:\n",
    "    detected_location = determine_location(bounding_box, image_width, image_height)\n",
    "    expected_location = expected_locations.get(text, \"unknown\")\n",
    "    print(f\"Text: '{text}'\")\n",
    "    print(f\"Detected Location: {detected_location}\")\n",
    "    print(f\"Expected Location: {expected_location}\")\n",
    "    print(f\"Match: {detected_location == expected_location}\")\n",
    "    print()"
   ],
   "id": "3562bdfb0213bd32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Seat\n",
      "Bounding Box: [60.0, 106.0, 231.0, 97.0, 236.0, 219.0, 65.0, 234.0]\n",
      "Text: Jeg\n",
      "Bounding Box: [116.0, 173.0, 219.0, 196.0, 210.0, 245.0, 112.0, 225.0]\n",
      "Text: Ateca\n",
      "Bounding Box: [626.0, 501.0, 953.0, 557.0, 935.0, 659.0, 609.0, 606.0]\n",
      "Text: 2019\n",
      "Bounding Box: [1061.0, 1022.0, 1379.0, 1028.0, 1376.0, 1140.0, 1058.0, 1133.0]\n",
      "\n",
      "Text: 'Seat'\n",
      "Detected Location: top-left\n",
      "Expected Location: top-left\n",
      "Match: True\n",
      "\n",
      "Text: 'Jeg'\n",
      "Detected Location: top-left\n",
      "Expected Location: unknown\n",
      "Match: False\n",
      "\n",
      "Text: 'Ateca'\n",
      "Detected Location: center\n",
      "Expected Location: center\n",
      "Match: True\n",
      "\n",
      "Text: '2019'\n",
      "Detected Location: bottom-right\n",
      "Expected Location: bottom-right\n",
      "Match: True\n",
      "\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<h3>3</h3>\n",
    "la exemplul cu poza mea imi adauga un cuvant in plus, si ar putea ca in loc sa-l adauge, sa verifice daca restul se potrivesc si atunci sa nu-l ia in considerare. Sau in lista de groundTruth sa le verifice pe toate, nu pe rand, si sa observe ca toate se potrivesc dar a gasit un cuvant in plus\n"
   ],
   "id": "73b9df1f47372bc9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
