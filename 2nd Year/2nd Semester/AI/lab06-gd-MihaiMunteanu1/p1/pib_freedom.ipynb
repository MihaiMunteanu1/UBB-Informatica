{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-16T10:12:46.473939Z",
     "start_time": "2025-04-16T10:12:28.628887Z"
    }
   },
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from math import sqrt"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T10:14:38.041289Z",
     "start_time": "2025-04-16T10:14:38.026340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot3Ddata(x1Train, x2Train, yTrain, x1Model=None, x2Model=None, yModel=None, x1Test=None, x2Test=None, yTest=None, title=None):\n",
    "    def remove_invalid_values(feature1, feature2, outputs):\n",
    "        new_feature1 = []\n",
    "        new_feature2 = []\n",
    "        new_outputs = []\n",
    "        for f1, f2, out in zip(feature1, feature2, outputs):\n",
    "            if f1 >= 0 and f2 >= 0 and out >= 0 and not (np.isnan(f1) or np.isnan(f2) or np.isnan(out)):\n",
    "                new_feature1.append(f1)\n",
    "                new_feature2.append(f2)\n",
    "                new_outputs.append(out)\n",
    "        return new_feature1, new_feature2, new_outputs\n",
    "\n",
    "    # Filter invalid values for training data\n",
    "    x1Train, x2Train, yTrain = remove_invalid_values(x1Train, x2Train, yTrain)\n",
    "    if x1Test is not None and x2Test is not None and yTest is not None:\n",
    "        x1Test, x2Test, yTest = remove_invalid_values(x1Test, x2Test, yTest)\n",
    "    if x1Model is not None and x2Model is not None and yModel is not None:\n",
    "        x1Model, x2Model, yModel = remove_invalid_values(x1Model, x2Model, yModel)\n",
    "\n",
    "    ax = plt.axes(projection='3d')\n",
    "    if x1Train:\n",
    "        ax.scatter(x1Train, x2Train, yTrain, c='r', marker='o', label='train data')\n",
    "    if x1Model:\n",
    "        ax.scatter(x1Model, x2Model, yModel, c='b', marker='_', label='learnt model')\n",
    "    if x1Test:\n",
    "        ax.scatter(x1Test, x2Test, yTest, c='g', marker='^', label='test data')\n",
    "    plt.title(title)\n",
    "    ax.set_xlabel(\"capita\")\n",
    "    ax.set_ylabel(\"freedom\")\n",
    "    ax.set_zlabel(\"happiness\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "id": "4c222e7db3c8cd0b",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T10:12:54.471246Z",
     "start_time": "2025-04-16T10:12:54.466883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plotDataHistogram(x, variableName):\n",
    "    n, bins, patches = plt.hist(x, 10)\n",
    "    plt.title('Histogram of ' + variableName)\n",
    "    plt.show()"
   ],
   "id": "fde0d2825d2c2686",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T10:46:26.700488Z",
     "start_time": "2025-04-16T10:46:26.692466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def loadDataMoreInputs(fileName, inputVariabNames, outputVariabName):\n",
    "    data = []\n",
    "    dataNames = []\n",
    "    with open(fileName) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            if line_count == 0:\n",
    "                dataNames = row\n",
    "            else:\n",
    "                data.append(row)\n",
    "            line_count += 1\n",
    "    selectedVariable1 = dataNames.index(inputVariabNames[0])\n",
    "    selectedVariable2 = dataNames.index(inputVariabNames[1])\n",
    "    inputs = [[float(data[i][selectedVariable1]), float(data[i][selectedVariable2])] for i in range(len(data))]\n",
    "    selectedOutput = dataNames.index(outputVariabName)\n",
    "    outputs = [float(data[i][selectedOutput]) for i in range(len(data))]\n",
    "\n",
    "    return inputs, outputs"
   ],
   "id": "17cc67ae27ff36d2",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T10:12:57.779990Z",
     "start_time": "2025-04-16T10:12:57.769881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalisation(trainData, testData):\n",
    "    scaler = StandardScaler()\n",
    "    if not isinstance(trainData[0], list):\n",
    "        # encode each sample into a list\n",
    "        trainData = [[d] for d in trainData]\n",
    "        testData = [[d] for d in testData]\n",
    "\n",
    "        scaler.fit(trainData)  # fit only on training data\n",
    "        normalisedTrainData = scaler.transform(trainData)  # apply same transformation to train data\n",
    "        normalisedTestData = scaler.transform(testData)  # apply same transformation to test data\n",
    "\n",
    "        # decode from list to raw values\n",
    "        normalisedTrainData = [el[0] for el in normalisedTrainData]\n",
    "        normalisedTestData = [el[0] for el in normalisedTestData]\n",
    "    else:\n",
    "        scaler.fit(trainData)  # fit only on training data\n",
    "        normalisedTrainData = scaler.transform(trainData)  # apply same transformation to train data\n",
    "        normalisedTestData = scaler.transform(testData)  # apply same transformation to test data\n",
    "    return normalisedTrainData, normalisedTestData"
   ],
   "id": "70a3c10f33296eb8",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T10:47:59.175725Z",
     "start_time": "2025-04-16T10:47:59.162458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from p1.BGD import MyBGDRegression\n",
    "from p1.SGD import MySGDRegression\n",
    "import numpy as np\n",
    "\n",
    "# load data\n",
    "crtDir = os.getcwd()\n",
    "filePath = os.path.join(crtDir, 'data', 'world-happiness-report-2017.csv')\n",
    "\n",
    "inputs, outputs = loadDataMoreInputs(filePath, ['Economy..GDP.per.Capita.', 'Freedom'], 'Happiness.Score')\n",
    "\n",
    "feature1 = [ex[0] for ex in inputs]\n",
    "feature2 = [ex[1] for ex in inputs]\n",
    "\n",
    "# plot the data histograms\n",
    "plotDataHistogram(feature1, 'capita GDP')\n",
    "plotDataHistogram(feature2, 'freedom')\n",
    "plotDataHistogram(outputs, 'Happiness score')\n",
    "\n",
    "# check the liniarity (to check that a linear relationship exists between the dependent variable (y = happiness) and the independent variables (x1 = capita, x2 = freedom).)\n",
    "plot3Ddata(feature1, feature2, outputs, [], [], [], [], [], [], 'capita vs freedom vs happiness')\n",
    "\n",
    "# split data into training data (80%) and testing data (20%) and normalise the data\n",
    "np.random.seed(5)\n",
    "indexes = [i for i in range(len(inputs))]\n",
    "trainSample = np.random.choice(indexes, int(0.8 * len(inputs)), replace=False)\n",
    "testSample = [i for i in indexes if not i in trainSample]\n",
    "\n",
    "trainInputs = [inputs[i] for i in trainSample]\n",
    "trainOutputs = [outputs[i] for i in trainSample]\n",
    "testInputs = [inputs[i] for i in testSample]\n",
    "testOutputs = [outputs[i] for i in testSample]\n",
    "\n",
    "trainInputs, testInputs = normalisation(trainInputs, testInputs)\n",
    "trainOutputs, testOutputs = normalisation(trainOutputs, testOutputs)\n",
    "\n",
    "feature1train = [ex[0] for ex in trainInputs]\n",
    "feature2train = [ex[1] for ex in trainInputs]\n",
    "\n",
    "feature1test = [ex[0] for ex in testInputs]\n",
    "feature2test = [ex[1] for ex in testInputs]\n",
    "\n",
    "plot3Ddata(feature1train, feature2train, trainOutputs, [], [], [], feature1test, feature2test, testOutputs,\n",
    "           \"train and test data (after normalisation)\")\n",
    "\n",
    "#training step\n",
    "model = 's'\n",
    "# model initialisation\n",
    "if (model == \"s\"):\n",
    "    regressor = MySGDRegression()\n",
    "else:\n",
    "    regressor = MyBGDRegression()\n",
    "\n",
    "regressor.fit(trainInputs, trainOutputs)\n",
    "# print(regressor.coef_)\n",
    "# print(regressor.intercept_)\n",
    "\n",
    "\n",
    "# parameters of the liniar regressor\n",
    "w0, w1, w2 = regressor.intercept_, regressor.coef_[0], regressor.coef_[1]\n",
    "print('the learnt model: f(x) = ', w0, ' + ', w1, ' * x1 + ', w2, ' * x2')\n",
    "\n",
    "# plot the model\n",
    "# numerical representation of the regressor model\n",
    "noOfPoints = 50\n",
    "xref1 = []\n",
    "val = min(feature1)\n",
    "step1 = (max(feature1) - min(feature1)) / noOfPoints\n",
    "for _ in range(1, noOfPoints):\n",
    "    for _ in range(1, noOfPoints):\n",
    "        xref1.append(val)\n",
    "    val += step1\n",
    "\n",
    "xref2 = []\n",
    "val = min(feature2)\n",
    "step2 = (max(feature2) - min(feature2)) / noOfPoints\n",
    "for _ in range(1, noOfPoints):\n",
    "    aux = val\n",
    "    for _ in range(1, noOfPoints):\n",
    "        xref2.append(aux)\n",
    "        aux += step2\n",
    "yref = [w0 + w1 * el1 + w2 * el2 for el1, el2 in zip(xref1, xref2)]\n",
    "plot3Ddata(feature1train, feature2train, trainOutputs, xref1, xref2, yref, [], [], [],\n",
    "           'train data and the learnt model')\n",
    "\n",
    "# use the trained model to predict new inputs\n",
    "\n",
    "# makes predictions for test data\n",
    "# computedTestOutputs = [w0 + w1 * el[0] + w2 * el[1] for el in testInputs]\n",
    "# makes predictions for test data (by tool)\n",
    "computedTestOutputs = regressor.predict(testInputs)\n",
    "\n",
    "plot3Ddata([], [], [], feature1test, feature2test, computedTestOutputs, feature1test, feature2test, testOutputs,\n",
    "           'predictions vs real test data')\n",
    "\n",
    "# compute the error\n",
    "# compute the differences between the predictions and real outputs\n",
    "error = 0.0\n",
    "for t1, t2 in zip(computedTestOutputs, testOutputs):\n",
    "    error += (t1 - t2) ** 2\n",
    "error = error / len(testOutputs)\n",
    "print('prediction error (manual): ', error)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "error = mean_squared_error(testOutputs, computedTestOutputs)\n",
    "print('prediction error (tool):   ', error)"
   ],
   "id": "6515474f0f59aa1b",
   "outputs": [],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
