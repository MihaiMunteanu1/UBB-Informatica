{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T11:13:48.821536Z",
     "start_time": "2025-04-16T11:13:48.780617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ],
   "id": "ca5abf18dfebf854",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T11:13:53.945753Z",
     "start_time": "2025-04-16T11:13:53.937261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def loadDataMoreInputs(fileName, inputVariabNames, outputVariabName, label_encoder):\n",
    "    data = []\n",
    "    dataNames = []\n",
    "    with open(fileName) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            if line_count == 0:\n",
    "                dataNames = row\n",
    "            else:\n",
    "                data.append(row)\n",
    "            line_count += 1\n",
    "    selectedVariables = [dataNames.index(var) for var in inputVariabNames]\n",
    "    inputs = [[float(data[i][var]) for var in selectedVariables] for i in range(len(data))]\n",
    "    selectedOutput = dataNames.index(outputVariabName)\n",
    "    outputs = [data[i][selectedOutput] for i in range(len(data))]\n",
    "\n",
    "    #from text to numeric inputs\n",
    "    outputs_encoded = label_encoder.fit_transform(outputs)\n",
    "\n",
    "    outputs_encoded = outputs_encoded.reshape(-1, 1)\n",
    "\n",
    "    return inputs, outputs_encoded"
   ],
   "id": "a5fe745ec3e524f5",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T14:11:58.383491Z",
     "start_time": "2025-04-16T14:11:57.272576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from MyLogisticRegressor import LogisticRegressorMultiClass\n",
    "\n",
    "crtDir = os.getcwd()\n",
    "filePath = os.path.join(crtDir, 'data', 'iris.csv')\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "inputs, outputs = loadDataMoreInputs(filePath, ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth'],\n",
    "                                     'Class', label_encoder)\n",
    "\n",
    "# split data into training data (80%) and testing data (20%) and normalise data\n",
    "np.random.seed(5)\n",
    "indexes = [i for i in range(len(inputs))]\n",
    "trainSample = np.random.choice(indexes, int(0.8 * len(inputs)), replace=False)\n",
    "testSample = [i for i in indexes if not i in trainSample]\n",
    "\n",
    "trainInputs = [inputs[i] for i in trainSample]\n",
    "trainOutputs = [outputs[i] for i in trainSample]\n",
    "trainOutputs = np.array(trainOutputs).ravel()\n",
    "testInputs = [inputs[i] for i in testSample]\n",
    "testOutputs = [outputs[i] for i in testSample]\n",
    "testOutputs = np.array(testOutputs).ravel()\n",
    "\n",
    "# normalization\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(trainInputs)\n",
    "trainInputs = scaler.transform(trainInputs)\n",
    "testInputs = scaler.transform(testInputs)\n",
    "\n",
    "\n",
    "# training step\n",
    "modelType = ''\n",
    "if modelType == \"tool\":\n",
    "    model = LogisticRegression()\n",
    "    model.fit(trainInputs, trainOutputs)\n",
    "    w0, w1 = model.intercept_, model.coef_[0]\n",
    "    print('the learnt model: f(x) = ', w0[0], ' + ', w1[0], ' * x1 + ', w1[1], ' * x2')\n",
    "else:\n",
    "    model = LogisticRegressorMultiClass(alpha=0.01, max_iter=1000, random_state=42)\n",
    "    model.fit(trainInputs, trainOutputs)\n",
    "    first_class = model.classes_[0]\n",
    "    first_model = model.models[first_class]\n",
    "    w0 = first_model.intercept_\n",
    "    w1 = first_model.coef_[0]\n",
    "    w2 = first_model.coef_[1]\n",
    "\n",
    "    print('the learnt model for class', first_class, ': f(x) = ', w0, ' + ', w1, ' * x1 + ', w2, ' * x2')\n",
    "\n",
    "\n",
    "computedTestOutputs = model.predict(testInputs)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(testOutputs, computedTestOutputs))\n",
    "print('Precision: ', precision_score(testOutputs, computedTestOutputs, average='weighted'))\n",
    "print('Recall: ', recall_score(testOutputs, computedTestOutputs, average='weighted'))\n",
    "\n",
    "\n",
    "\n",
    "normalized_inputs = scaler.transform([[5.35, 3.85, 1.25, 0.4]])\n",
    "prediction = model.predict(np.array(normalized_inputs))\n",
    "predicted_species = label_encoder.inverse_transform(prediction)\n",
    "print(\"Result: \", predicted_species[0])\n",
    "\n",
    "\n"
   ],
   "id": "d0a47793a46026de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the learnt model for class 0 : f(x) =  -0.7952443678448354  +  -0.6378594334897498  * x1 +  0.9173326420289316  * x2\n",
      "Accuracy:  0.8\n",
      "Precision:  0.7911111111111111\n",
      "Recall:  0.8\n",
      "Result:  Iris-setosa\n"
     ]
    }
   ],
   "execution_count": 29
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
