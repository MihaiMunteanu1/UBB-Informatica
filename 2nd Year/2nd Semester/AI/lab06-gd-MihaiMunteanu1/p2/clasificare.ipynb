{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:12:28.846165Z",
     "start_time": "2025-04-16T12:12:28.839968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "id": "c71131b65cabc73f",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:12:29.608756Z",
     "start_time": "2025-04-16T12:12:29.595968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plotDataHistogram(x, variableName):\n",
    "    n, bins, patches = plt.hist(x, 10)\n",
    "    plt.title('Histogram of ' + variableName)\n",
    "    plt.show()"
   ],
   "id": "84302cbf28d5deed",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:12:30.312950Z",
     "start_time": "2025-04-16T12:12:30.299640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def loadDataMoreInputs(fileName, inputVariabNames, outputVariabName):\n",
    "    data = []\n",
    "    dataNames = []\n",
    "    with open(fileName) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            if line_count == 0:\n",
    "                dataNames = row\n",
    "            else:\n",
    "                data.append(row)\n",
    "            line_count += 1\n",
    "    selectedVariable1 = dataNames.index(inputVariabNames[0])\n",
    "    selectedVariable2 = dataNames.index(inputVariabNames[1])\n",
    "    inputs = [[float(data[i][selectedVariable1]), float(data[i][selectedVariable2])] for i in range(len(data))]\n",
    "    selectedOutput = dataNames.index(outputVariabName)\n",
    "    outputs = [1 if data[i][selectedOutput] == 'M' else 0 for i in range(len(data))]\n",
    "\n",
    "    return inputs, outputs"
   ],
   "id": "d8a4bfd9dc4c4f60",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T14:14:29.056014Z",
     "start_time": "2025-04-16T14:14:29.034133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from MyLogisticRegressor import LogisticRegressorBinary\n",
    "\n",
    "crtDir = os.getcwd()\n",
    "filePath = os.path.join(crtDir, 'data', 'wdbc.csv')\n",
    "\n",
    "inputs, outputs = loadDataMoreInputs(filePath, ['Radius', 'Texture'], 'Diagnosis')\n",
    "\n",
    "# split data into training data (80%) and testing data (20%) and normalise data\n",
    "np.random.seed(5)\n",
    "indexes = [i for i in range(len(inputs))]\n",
    "trainSample = np.random.choice(indexes, int(0.8 * len(inputs)), replace=False)\n",
    "testSample = [i for i in indexes if not i in trainSample]\n",
    "\n",
    "trainInputs = [inputs[i] for i in trainSample]\n",
    "trainOutputs = [outputs[i] for i in trainSample]\n",
    "testInputs = [inputs[i] for i in testSample]\n",
    "testOutputs = [outputs[i] for i in testSample]\n",
    "\n",
    "# normalization\n",
    "scaler = StandardScaler()\n",
    "if not isinstance(trainInputs[0], list):\n",
    "    trainInputs = [[d] for d in trainInputs]\n",
    "    testInputs = [[d] for d in testInputs]\n",
    "\n",
    "    scaler.fit(trainInputs)\n",
    "    trainInputs = scaler.transform(trainInputs)\n",
    "    testInputs = scaler.transform(testInputs)\n",
    "\n",
    "    trainInputs = [el[0] for el in trainInputs]\n",
    "    testInputs = [el[0] for el in testInputs]\n",
    "else:\n",
    "    scaler.fit(trainInputs)\n",
    "    trainInputs = scaler.transform(trainInputs)\n",
    "    testInputs = scaler.transform(testInputs)\n",
    "\n",
    "modelType = 'tool'\n",
    "# training step\n",
    "if modelType == \"tool\":\n",
    "    model = LogisticRegression()\n",
    "    model.fit(trainInputs, trainOutputs)\n",
    "    w0, w1 = model.intercept_, model.coef_[0]\n",
    "    print('the learnt model: f(x) = ', w0[0], ' + ', w1[0], ' * x1 + ', w1[1], ' * x2')\n",
    "else:\n",
    "    model = LogisticRegressorBinary()\n",
    "    trainOutputs = np.array(trainOutputs)\n",
    "    model.fit(trainInputs, trainOutputs)\n",
    "    w0 = model.intercept_\n",
    "    w1 = model.coef_[0]\n",
    "    w2 = model.coef_[1]\n",
    "    print('the learnt model: f(x) = ', w0, ' + ', w1, ' * x1 + ', w2, ' * x2')\n",
    "\n",
    "computedTestOutputs = model.predict(testInputs)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(testOutputs, computedTestOutputs))\n",
    "print('Precision: ', precision_score(testOutputs, computedTestOutputs))\n",
    "print('Recall: ', recall_score(testOutputs, computedTestOutputs))\n",
    "\n",
    "normalized_inputs = scaler.transform([[18, 10]])\n",
    "prediction = model.predict(np.array(normalized_inputs))\n",
    "if prediction[0] == 0:\n",
    "    print(\"Result: benign.\")\n",
    "else:\n",
    "    print(\"Result: malign.\")\n",
    "\n",
    "\n"
   ],
   "id": "ff3de29900428327",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the learnt model: f(x) =  -0.9122440356107672  +  3.714265538441941  * x1 +  0.9215248354552286  * x2\n",
      "Accuracy:  0.7982456140350878\n",
      "Precision:  0.8461538461538461\n",
      "Recall:  0.66\n",
      "Result: malign.\n"
     ]
    }
   ],
   "execution_count": 71
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
